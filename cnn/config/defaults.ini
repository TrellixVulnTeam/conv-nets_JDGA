#########################
## DEFAULT CONFIGURATION
#########################
## THIS FILE PROVIDES DEFAULT CONFIGURATION SETTINGS FOR MODELS. DO NOT EDIT.

# If you wish to specify your own settings, create a new .ini config file with
# the parameters you wish to override, or pass them in as keyword arguments.
# See ModelConfig for details. Make sure to follow the format of this file
# when creating new configuration files. Do not forget to include a section
# header. See https://docs.python.org/3/library/configparser.html for info.


[model_config]
#########################
## MODEL SETTINGS
#########################
# See cnn.input.get_dataset for available dataset names
dataset_name = cifar10
# Whether currently existing datasets should be deleted and rewritten
overwrite = False
# One of 'train', 'test', or 'valid'; the phase to run the model in
phase = train
# See cnn.model.get_model for available model architecture types
model_type = simple
# Either 'SAME' or 'VALID'; default padding method used for layers
padding_mode = SAME


#########################
## FILE LOCATIONS
#########################
# Dataset location
data_dir = data/
# Checkpoint saving/restoring location; should likely be same as summaries_dir
checkpoints_dir = logs/
# TensorBoard summaries location; should likely be same as checkpoints_dir
summaries_dir = logs/


#########################
## DATA PROCESSING
#########################
# Number of examples run on *each* device per batch
batch_size = 128
# Whether images should be distorted in preprocessing of training batches
distort_images = True
# Number of threads to use for data processing; only change if I/O bottlenecked
num_preprocessing_threads = 32
# Min fraction of examples that must be present in data buffer for shuffling
min_example_fraction = 0.4
# NCHW or NHWC; for better performance, use NCHW on GPU runs, and NHWC on CPU
data_format = NHWC
# float{16,32,64}; don't change without specific reason (e.g. quantization)
data_type = float32


#########################
## COMPUTER SETTINGS
#########################
# Number of GPUs to parallelize training across; 0 to run just on the CPU
num_gpus = 0


#########################
## TRAINING PARAMETERS
#########################
## These values are decent initial guesses, but should likely be adjusted based
## on the specifics of the model being trained and dataset used.

# Initial learning rate of model
init_learning_rate = 0.1
# Rate used for exponential decay of learning rate
learning_decay_rate = 0.95
# Number of epochs that elapse per decay step
epochs_per_decay = 10
# Weight decay regularization rate
weight_decay_rate = 0.004
# Decay rate used for keeping moving averages of variables
moving_avg_decay_rate = 0.99


#########################
## TESTING PARAMETERS
#########################
## Controls testing parameters, and settings for background validation testing

# Check percent of labels in top k predictions for each of following k
top_k_tests = 1,3,5
# Whether to restore averaged or raw variables for evaluation
restore_moving_averages = True
# Fraction of validation set to use when running in background of training
# Always uses entire validation set when not run in background
bg_valid_set_fraction = 1.0
# How frequently to run model validation process in background (0 to turn off)
bg_valid_repeat_secs = 120


#########################
## LOGGING
#########################
## If any of following values are 0, their logging step will not be performed
## Logging only occurs during training phase

# Whether device placement should be logged
log_device_placement = False
# Print basic info to terminal each time this number of steps elapses
print_log_steps = 10
# Save checkpoints each time this number of seconds elapses
save_checkpoint_secs = 600
# Save TensorBoard summaries each time this number of steps elapses
save_summaries_steps = 100



